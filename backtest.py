import torch
from torch.utils.data import DataLoader
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import torch.nn.functional as F  # æ–°å¢

# ç¢ºä¿è·¯å¾‘æ­£ç¢º
from features.alignment import synthesize_mtf_data
from features.preprocess import prepare_features
from models.tcn_core import ParallelTCNAlphaHunter
from data.dataset import CryptoTimeSeriesDataset
from train import load_and_clean_data, CONFIG

def run_vectorized_backtest(asset_name='BTCUSDT', fee_rate=0.001, threshold=0.0):
    """
    Args:
        threshold: ä¿¡å¿ƒé–€æª» (0.0 ä»£è¡¨ä¸è¨­é™)ã€‚å¦‚æœæ¨¡å‹æœ€å¤§æ©Ÿç‡ < thresholdï¼Œå‰‡å¼·åˆ¶ Holdã€‚
    """
    print(f"ğŸ§ª é–‹å§‹å›æ¸¬: {asset_name} | æ‰‹çºŒè²»: {fee_rate*100:.2f}% | ä¿¡å¿ƒé–€æª»: {threshold}")
    
    # 1. è¼‰å…¥èˆ‡è™•ç†æ•¸æ“š
    filepath = os.path.join('data', 'raw', f'{asset_name}_1H.csv')
    if not os.path.exists(filepath):
        # å˜—è©¦ç›´æ¥è®€å–ä»£ç¢¼æ‰€åœ¨ç›®éŒ„
        filepath = f'{asset_name}_1H.csv'
        if not os.path.exists(filepath):
            print(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“š: {filepath}")
            return

    df = load_and_clean_data(filepath)
    print("ğŸ”„ è™•ç†ç‰¹å¾µ...")
    df_aligned = synthesize_mtf_data(df)
    
    # ä¿ç•™åŸå§‹æ•¸æ“šä¾›å¾ŒçºŒåˆ†æ
    raw_df = df_aligned[['open', 'high', 'low', 'close']].copy()
    
    df_features = prepare_features(df_aligned, method=CONFIG['norm_method'], window=30)
    df_features = df_features.dropna()
    
    # æ³¨å…¥ Dummy Label
    if 'label' not in df_features.columns:
        df_features['label'] = 0
    
    # å°é½ŠåŸå§‹åƒ¹æ ¼
    raw_df = raw_df.loc[df_features.index]
    
    # 2. è¼‰å…¥æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ’» ä½¿ç”¨è£ç½®: {device}")
    
    model = ParallelTCNAlphaHunter(input_features=5, num_classes=3).to(device)
    
    # å°‹æ‰¾æ¨¡å‹è·¯å¾‘
    possible_paths = [
        os.path.join('models', 'checkpoints', 'best_model.pth'),
        'best_model.pth'
    ]
    checkpoint_path = next((p for p in possible_paths if os.path.exists(p)), None)
    
    if checkpoint_path:
        print(f"ğŸ”„ è¼‰å…¥æ¨¡å‹: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=device)
        state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
        model.load_state_dict(state_dict)
    else:
        print("âŒ æ‰¾ä¸åˆ° best_model.pth")
        return

    model.eval()
    
    # 3. æ¨è«– (å«ä¿¡å¿ƒåº¦)
    dataset = CryptoTimeSeriesDataset(df_features, seq_len=CONFIG['seq_len'])
    loader = DataLoader(dataset, batch_size=256, shuffle=False)
    
    all_preds = []
    all_probs = [] # å„²å­˜ä¿¡å¿ƒåº¦
    
    print("ğŸ”® åŸ·è¡Œæ¨è«–...")
    with torch.no_grad():
        for batch in loader:
            x_1h = batch['1h'].to(device)
            x_4h = batch['4h'].to(device)
            x_1d = batch['1d'].to(device)
            
            logits = model(x_1h, x_4h, x_1d)
            probs = F.softmax(logits, dim=1) # è½‰æˆæ©Ÿç‡
            
            # å–å¾—æœ€å¤§æ©Ÿç‡èˆ‡å°æ‡‰é¡åˆ¥
            max_probs, preds = torch.max(probs, dim=1)
            
            # å¦‚æœä¿¡å¿ƒä¸è¶³ï¼Œå¼·åˆ¶è½‰ç‚º Hold (0)
            if threshold > 0:
                mask = max_probs < threshold
                preds[mask] = 0
                
            all_preds.extend(preds.cpu().numpy())
            all_probs.extend(max_probs.cpu().numpy())
            
    # 4. æ§‹å»ºè©³ç´°æ—¥èªŒ (Trade Log)
    valid_len = len(all_preds)
    # æ™‚é–“ç´¢å¼•å¾ seq_len ä¹‹å¾Œé–‹å§‹
    log_index = df_features.index[CONFIG['seq_len'] : CONFIG['seq_len']+valid_len]
    
    log_df = pd.DataFrame(index=log_index)
    log_df['Close'] = raw_df['close'].iloc[CONFIG['seq_len'] : CONFIG['seq_len']+valid_len].values
    log_df['Signal'] = all_preds
    log_df['Confidence'] = all_probs
    
    # æ˜ å°„è¨Šè™Ÿ: 0->0 (Hold), 1->1 (Long), 2->-1 (Short)
    log_df['Position'] = log_df['Signal'].map({0: 0, 1: 1, 2: -1})
    
    # è¨ˆç®—å›å ±
    log_df['Market_Ret'] = np.log(log_df['Close'] / log_df['Close'].shift(1)).fillna(0)
    # ç­–ç•¥å›å ± = æ˜¨å¤©çš„éƒ¨ä½ * ä»Šå¤©çš„æ¼²è·Œ
    log_df['Strategy_Ret'] = log_df['Position'].shift(1) * log_df['Market_Ret']
    
    # è¨ˆç®—æ‰‹çºŒè²»
    log_df['Pos_Change'] = log_df['Position'].diff().abs().fillna(0)
    log_df['Fees'] = log_df['Pos_Change'] * fee_rate
    log_df['Net_Ret'] = log_df['Strategy_Ret'] - log_df['Fees']
    
    # ç´¯è¨ˆæ·¨å€¼
    log_df['Equity'] = (1 + log_df['Net_Ret']).cumprod()
    log_df['Market_Equity'] = (1 + log_df['Market_Ret']).cumprod()
    
    # 5. è¼¸å‡ºå ±å‘Šèˆ‡æª”æ¡ˆ
    total_ret = log_df['Equity'].iloc[-1] - 1
    mkt_ret = log_df['Market_Equity'].iloc[-1] - 1
    
    print("\n" + "="*30)
    print(f"ğŸ“Š è©³ç´°å›æ¸¬å ±å‘Š: {asset_name}")
    print(f"   ç¸½å›å ±: {total_ret*100:.2f}% (åŸºæº–: {mkt_ret*100:.2f}%)")
    print(f"   ç¸½äº¤æ˜“æ¬¡æ•¸: {log_df['Pos_Change'].sum()/2:.0f}")
    print(f"   å¹³å‡ä¿¡å¿ƒåº¦: {np.mean(all_probs):.4f}")
    print("="*30)

    # å„²å­˜è©³ç´°æ—¥èªŒ CSV
    csv_filename = f'backtest_log_{asset_name}.csv'
    log_df.to_csv(csv_filename)
    print(f"ğŸ’¾ äº¤æ˜“æ—¥èªŒå·²å„²å­˜: {csv_filename} (è«‹ä¸‹è¼‰ä¸¦ç”¨ Excel æ‰“é–‹åˆ†æ)")
    
    # ç¹ªåœ–
    plt.figure(figsize=(12, 6))
    plt.plot(log_df.index, log_df['Market_Equity'], label='Market', alpha=0.5, color='gray')
    plt.plot(log_df.index, log_df['Equity'], label='Strategy', linewidth=1.5, color='blue')
    plt.title(f'Equity Curve: {asset_name} (Thresh={threshold})')
    plt.yscale('log') # ä½¿ç”¨å°æ•¸åæ¨™çœ‹æ¸…æ¥šè™§æ
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(f'backtest_{asset_name}.png')

if __name__ == "__main__":
    # å˜—è©¦æé«˜é–€æª»ï¼Œæ¸›å°‘éš¨æ©Ÿäº¤æ˜“
    run_vectorized_backtest('BTCUSDT', fee_rate=0.001, threshold=0.0)
    run_vectorized_backtest('ETHUSDT', fee_rate=0.001, threshold=0.0)