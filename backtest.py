import torch
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt

# ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼Œæ ¹æ“šä½ çš„ç’°å¢ƒå¯èƒ½éœ€è¦èª¿æ•´ import
from features.alignment import synthesize_mtf_data
from features.preprocess import prepare_features
from models.tcn_core import ParallelTCNAlphaHunter
from data.dataset import CryptoTimeSeriesDataset
from train import load_and_clean_data, CONFIG

def run_vectorized_backtest(asset_name='BTCUSDT', fee_rate=0.001):
    """
    å‘é‡åŒ–å›æ¸¬ï¼šå¿«é€Ÿé©—è­‰æ¨¡å‹åœ¨å–®ä¸€è³‡ç”¢ä¸Šçš„ç¸¾æ•ˆ
    Args:
        asset_name: è³‡ç”¢åç¨±
        fee_rate: æ‰‹çºŒè²»ç‡ (0.001 = 0.1%)
    """
    print(f"ğŸ§ª é–‹å§‹å›æ¸¬: {asset_name} | æ‰‹çºŒè²»: {fee_rate*100:.2f}%")
    
    # 1. è¼‰å…¥æ•¸æ“š
    filepath = os.path.join('data', 'raw', f'{asset_name}_1H.csv')
    if not os.path.exists(filepath):
        print(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“š: {filepath}")
        # Colab è·¯å¾‘å®¹éŒ¯ (æœ‰æ™‚å€™ç”¨æˆ¶æœƒæ”¾åœ¨ content æ ¹ç›®éŒ„)
        filepath = f'{asset_name}_1H.csv'
        if not os.path.exists(filepath):
            print(f"âŒ ä¹Ÿæ‰¾ä¸åˆ°æ ¹ç›®éŒ„æ•¸æ“š: {filepath}ï¼Œçµ‚æ­¢ã€‚")
            return
        else:
            print(f"âœ… åœ¨æ ¹ç›®éŒ„æ‰¾åˆ°æ•¸æ“š: {filepath}")

    df = load_and_clean_data(filepath)
    
    # 2. ç‰¹å¾µå·¥ç¨‹ (å¿…é ˆèˆ‡è¨“ç·´æ™‚å®Œå…¨ä¸€è‡´)
    print("ğŸ”„ è™•ç†ç‰¹å¾µ...")
    df_aligned = synthesize_mtf_data(df)
    
    # ä¿ç•™ Close ç”¨æ–¼è¨ˆç®—æç›Š (éœ€èˆ‡ Feature å°é½Š)
    raw_close = df_aligned['close'].copy()
    
    # ç”Ÿæˆç‰¹å¾µ (æ³¨æ„ï¼šå›æ¸¬æ™‚é€šå¸¸æ²’æœ‰ labelï¼Œprepare_features æœƒè™•ç†ç‰¹å¾µéƒ¨åˆ†)
    df_features = prepare_features(df_aligned, method=CONFIG['norm_method'], window=30)
    df_features = df_features.dropna()
    
    # --- é—œéµä¿®å¾©ï¼šæ³¨å…¥ Dummy Label ---
    # CryptoTimeSeriesDataset é è¨­éœ€è¦ 'label' æ¬„ä½ï¼Œå¦å‰‡æœƒå ± KeyError
    if 'label' not in df_features.columns:
        # å¡«å…¥ 0 (Hold) ä½œç‚ºä½”ä½ç¬¦ï¼Œé€™ä¸æœƒå½±éŸ¿æ¨¡å‹æ¨è«–(Inference)
        df_features['label'] = 0
        print("ğŸ”§ å·²æ³¨å…¥ Dummy Label ä»¥ç¬¦åˆ Dataset æ ¼å¼è¦æ±‚")
    
    # å°é½Š raw_close (å› ç‚º dropna ç§»é™¤äº†éƒ¨åˆ†æ•¸æ“š)
    raw_close = raw_close.loc[df_features.index]
    
    # 3. è¼‰å…¥æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ’» ä½¿ç”¨è£ç½®: {device}")
    
    model = ParallelTCNAlphaHunter(input_features=5, num_classes=3).to(device)
    
    # æ”¯æ´å¤šç¨®è·¯å¾‘æª¢æŸ¥
    possible_paths = [
        os.path.join('models', 'checkpoints', 'best_model.pth'),
        'best_model.pth', # Colab æ ¹ç›®éŒ„
        '/content/models/checkpoints/best_model.pth'
    ]
    
    checkpoint_path = None
    for p in possible_paths:
        if os.path.exists(p):
            checkpoint_path = p
            break
            
    if checkpoint_path:
        print(f"ğŸ”„ è¼‰å…¥æ¨¡å‹: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=device)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    else:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹ Checkpoint (best_model.pth)")
        return

    model.eval()
    
    # 4. æ‰¹é‡é æ¸¬ (Batch Inference)
    dataset = CryptoTimeSeriesDataset(df_features, seq_len=CONFIG['seq_len'])
    loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False)
    
    all_preds = []
    
    print("ğŸ”® åŸ·è¡Œæ¨è«–...")
    with torch.no_grad():
        for batch in loader:
            x_1h = batch['1h'].to(device)
            x_4h = batch['4h'].to(device)
            x_1d = batch['1d'].to(device)
            
            logits = model(x_1h, x_4h, x_1d)
            preds = torch.argmax(logits, dim=1).cpu().numpy()
            all_preds.extend(preds)
            
    # 5. è¨ˆç®—å›æ¸¬é‚è¼¯
    # æ³¨æ„: dataset[i] çš„æ•¸æ“šæ™‚é–“é»æ˜¯ Tï¼Œæ¨™ç±¤æ˜¯å°æ‡‰ T+1 ä¹‹å¾Œçš„æœªä¾†
    # æˆ‘å€‘çš„æ¨¡å‹åœ¨ T æ™‚åˆ»çµ¦å‡ºé æ¸¬ï¼Œæˆ‘å€‘åœ¨ T+1 é–‹ç›¤åŸ·è¡Œ
    
    valid_len = len(all_preds)
    
    # åˆ†æç”¨çš„ DataFrame (å¾ seq_len ä¹‹å¾Œé–‹å§‹)
    analysis_df = pd.DataFrame(index=df_features.index[CONFIG['seq_len']:])
    
    # è£åˆ‡é•·åº¦ä»¥åŒ¹é…é æ¸¬çµæœ
    analysis_df = analysis_df.iloc[:valid_len].copy()
    analysis_df['close'] = raw_close.iloc[CONFIG['seq_len']:].iloc[:valid_len].values
    analysis_df['signal_idx'] = all_preds 
    
    # æ˜ å°„è¨Šè™Ÿ: 0->0, 1->1 (Buy), 2->-1 (Sell)
    # å‡è¨­ dataset.py è£¡çš„è½‰æ›é‚è¼¯æ˜¯: -1 -> 2, 0 -> 0, 1 -> 1
    # æ‰€ä»¥é€™è£¡è¦è½‰å›ä¾†: 2 -> -1
    signal_map = {0: 0, 1: 1, 2: -1}
    analysis_df['position'] = analysis_df['signal_idx'].map(signal_map)
    
    # è¨ˆç®—å¸‚å ´å›å ± (Log Return)
    analysis_df['market_return'] = np.log(analysis_df['close'] / analysis_df['close'].shift(1)).fillna(0)
    
    # ç­–ç•¥å›å ±
    # é—œéµï¼šä»Šå¤©çš„ Position æ˜¯ç”±æ˜¨å¤©çš„æ•¸æ“šé æ¸¬å‡ºä¾†çš„ (shift(1))
    # é€™æ¨£æˆ‘å€‘æ‰èƒ½åƒåˆ°ä»Šå¤©çš„ market_return
    analysis_df['strategy_return'] = analysis_df['position'].shift(1) * analysis_df['market_return']
    
    # è¨ˆç®—æ‰‹çºŒè²» (åªæœ‰ç•¶æŒå€‰æ”¹è®Šæ™‚æ‰æ‰£è²»)
    analysis_df['position_change'] = analysis_df['position'].diff().abs().fillna(0)
    analysis_df['fees'] = analysis_df['position_change'] * fee_rate
    
    analysis_df['net_return'] = analysis_df['strategy_return'] - analysis_df['fees']
    
    # ç´¯è¨ˆå›å ± (æ¬Šç›Šæ›²ç·š)
    analysis_df['cum_market_return'] = analysis_df['market_return'].cumsum().apply(np.exp)
    analysis_df['cum_strategy_return'] = analysis_df['net_return'].cumsum().apply(np.exp)
    
    # 6. ç¸¾æ•ˆæŒ‡æ¨™
    total_ret = analysis_df['cum_strategy_return'].iloc[-1] - 1
    # å¤æ™®ç‡ (å‡è¨­ç„¡é¢¨éšªåˆ©ç‡ç‚º 0ï¼ŒæŒ‰å°æ™‚æ•¸æ“šå¹´åŒ–)
    sharpe = analysis_df['net_return'].mean() / (analysis_df['net_return'].std() + 1e-9) * np.sqrt(365*24)
    
    # å‹ç‡ (ä¸å« Hold)
    trade_returns = analysis_df[analysis_df['position'].shift(1) != 0]['net_return']
    win_rate = (trade_returns > 0).mean() if len(trade_returns) > 0 else 0
    
    print("\n" + "="*30)
    print(f"ğŸ“Š å›æ¸¬çµæœ: {asset_name}")
    print(f"   ç¸½å›å ±: {total_ret*100:.2f}%")
    print(f"   å¤æ™®ç‡: {sharpe:.2f}")
    print(f"   äº¤æ˜“å‹ç‡: {win_rate*100:.2f}% (æœ‰é–‹å€‰çš„æ™‚åˆ»)")
    print(f"   Buy & Hold: {(analysis_df['cum_market_return'].iloc[-1]-1)*100:.2f}%")
    print("="*30 + "\n")

    # ç¹ªåœ–
    plt.figure(figsize=(12, 6))
    plt.plot(analysis_df.index, analysis_df['cum_market_return'], label='Buy & Hold', alpha=0.5)
    plt.plot(analysis_df.index, analysis_df['cum_strategy_return'], label='Alpha Hunter', linewidth=2)
    plt.title(f'Alpha Hunter Strategy Equity Curve ({asset_name})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    output_img = f'backtest_{asset_name}.png'
    plt.savefig(output_img)
    print(f"ğŸ“ˆ æ¬Šç›Šæ›²ç·šå·²ä¿å­˜è‡³ {output_img}")

if __name__ == "__main__":
    # run_vectorized_backtest('BTCUSDT')
    run_vectorized_backtest('ETHUSDT')